{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "048e0be3-798b-45b0-a66a-ee268130156d",
   "metadata": {},
   "source": [
    "Parte 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a4d77ea1-4c99-499e-8649-009d3bfdc51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "67c29e69-a128-426b-8f6a-e3c8aeb6df64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['CODUSU', 'ANO4', 'TRIMESTRE', 'NRO_HOGAR', 'REALIZADA', 'REGION',\n",
      "       'MAS_500', 'AGLOMERADO', 'PONDERA', 'IV1', 'IV1_ESP', 'IV2', 'IV3',\n",
      "       'IV3_ESP', 'IV4', 'IV5', 'IV6', 'IV7', 'IV7_ESP', 'IV8', 'IV9', 'IV10',\n",
      "       'IV11', 'IV12_1', 'IV12_2', 'IV12_3', 'II1', 'II2', 'II3', 'II3_1',\n",
      "       'II4_1', 'II4_2', 'II4_3', 'II5', 'II5_1', 'II6', 'II6_1', 'II7',\n",
      "       'II7_ESP', 'II8', 'II8_ESP', 'II9', 'V1', 'V2', 'V21', 'V22', 'V3',\n",
      "       'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14',\n",
      "       'V15', 'V16', 'V17', 'V18', 'V19_A', 'V19_B', 'IX_TOT', 'IX_MEN10',\n",
      "       'IX_MAYEQ10', 'ITF', 'DECIFR', 'IDECIFR', 'RDECIFR', 'GDECIFR',\n",
      "       'PDECIFR', 'ADECIFR', 'IPCF', 'DECCFR', 'IDECCFR', 'RDECCFR', 'GDECCFR',\n",
      "       'PDECCFR', 'ADECCFR', 'PONDIH', 'VII1_1', 'VII1_2', 'VII2_1', 'VII2_2',\n",
      "       'VII2_3', 'VII2_4'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "directorio = \"C:\\\\Users\\\\Santiago\\\\Desktop\\\\2024\\\\1er cuatri\\\\Big Data\\\\Big-Data-TP3\\\\EPH_usu_4to_Trim_2023_xlsx\\\\usu_hogar_T423.xlsx\"\n",
    "archivo_excel= 'usu_individual_T423.xlsx'\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ed5f34f5-4a71-435d-8c83-0ff20ecf8b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           CODUSU  ANO4  TRIMESTRE  NRO_HOGAR  REALIZADA  \\\n",
      "27  TQRMNOSPPHLNMQCDEIJAH00854986  2023          4          1          1   \n",
      "28  TQRMNOTQWHMKMQCDEIJAH00812571  2023          4          1          1   \n",
      "43  TQRMNOQRWHLMOLCDEIJAH00855003  2023          4          1          1   \n",
      "44  TQRMNOPWUHJKOUCDEIJAH00855004  2023          4          1          1   \n",
      "45  TQRMNORTWHJMPOCDEIJAH00802523  2023          4          1          1   \n",
      "\n",
      "    REGION MAS_500  AGLOMERADO  PONDERA  IV1  ... GDECCFR  PDECCFR  ADECCFR  \\\n",
      "27       1       S          33     2431    1  ...     1.0      NaN        1   \n",
      "28       1       S          33     4054    1  ...     9.0      NaN        9   \n",
      "43       1       S          33     2142    1  ...     3.0      NaN        4   \n",
      "44       1       S          33     2860    2  ...     7.0      NaN        7   \n",
      "45       1       S          33     2310    1  ...     4.0      NaN        4   \n",
      "\n",
      "   PONDIH  VII1_1  VII1_2  VII2_1  VII2_2 VII2_3  VII2_4  \n",
      "27   3628       1       0       2       0      0       0  \n",
      "28   6943       1       2      98       0      0       0  \n",
      "43   5401       2       0      98       0      0       0  \n",
      "44   3361       1       0      98       0      0       0  \n",
      "45   3167       2       0      98       0      0       0  \n",
      "\n",
      "[5 rows x 88 columns]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'CH06'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3791\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3790\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3791\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3792\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'CH06'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[62], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m df_filtrado \u001b[38;5;241m=\u001b[39m df_filtrado[df_filtrado[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mITF\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Edad \u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m df_filtrado \u001b[38;5;241m=\u001b[39m df_filtrado[df_filtrado[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCH06\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Horas trabajadas \u001b[39;00m\n\u001b[0;32m     16\u001b[0m df_filtrado \u001b[38;5;241m=\u001b[39m df_filtrado[(df_filtrado[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPP3E_TOT\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m&\u001b[39m (df_filtrado[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPP3E_TOT\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m168\u001b[39m)]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3893\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3891\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3892\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3893\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   3894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3895\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3798\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3793\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3794\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3795\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3796\u001b[0m     ):\n\u001b[0;32m   3797\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3798\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3799\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3800\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3801\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3803\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'CH06'"
     ]
    }
   ],
   "source": [
    "#1.2 \n",
    "#a\n",
    "df_filtrado = df[df['REGION'] == 1]\n",
    "print(df_filtrado.head())\n",
    "\n",
    "#b \n",
    "\n",
    "#Ingresos \n",
    "df_filtrado = df_filtrado[df_filtrado['IPCF'] >= 0]\n",
    "df_filtrado = df_filtrado[df_filtrado['ITF'] >= 0]\n",
    "\n",
    "# Edad \n",
    "df_filtrado = df_filtrado[df_filtrado['CH06'] >= 0]\n",
    "\n",
    "# Horas trabajadas \n",
    "df_filtrado = df_filtrado[(df_filtrado['PP3E_TOT'] >= 0) & (df_filtrado['PP3E_TOT'] <= 168)]\n",
    "df_filtrado = df_filtrado[(df_filtrado['PP3F_TOT'] >= 0) & (df_filtrado['PP3F_TOT'] <= 168)]\n",
    "\n",
    "\n",
    "print(df_filtrado.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9e5f2ac7-dbae-4fc5-afb9-f95ffbc5ac66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de personas que no respondieron cuál es su ingreso total familiar (ITF): 3831\n"
     ]
    }
   ],
   "source": [
    "#1.3 \n",
    "\n",
    "# Especifica la ruta completa al archivo si no está en el mismo directorio\n",
    "file_path = 'C:\\\\Users\\\\Santiago\\\\Desktop\\\\2024\\\\1er cuatri\\\\Big Data\\\\Big-Data-TP3\\\\EPH_usu_4to_Trim_2023_xlsx\\\\usu_hogar_T423.xlsx'\n",
    "\n",
    "# Leer el archivo Excel\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Supongamos que la columna de Ingreso Total Familiar se llama 'ITF'\n",
    "# Ajusta el nombre de la columna si es diferente\n",
    "itf_column = 'ITF'\n",
    "\n",
    "# Filtrar las observaciones donde se reportó el ITF\n",
    "respondieron = df[df[itf_column] != 0]\n",
    "\n",
    "# Filtrar las observaciones donde el ITF es 0\n",
    "no_respondieron = df[df[itf_column] == 0]\n",
    "\n",
    "# Guardar los conjuntos de datos en archivos separados\n",
    "respondieron.to_excel('respondieron.xlsx', index=False)\n",
    "no_respondieron.to_excel('norespondieron.xlsx', index=False)\n",
    "\n",
    "# Contar las personas que no respondieron sobre su ITF\n",
    "personas_no_respondieron = no_respondieron.shape[0]\n",
    "\n",
    "print(f'Cantidad de personas que no respondieron cuál es su ingreso total familiar (ITF): {personas_no_respondieron}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b64988c2-0390-4a20-a24d-7f05fba9c808",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ad_equiv_por_hogar' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[61], line 14\u001b[0m\n\u001b[0;32m      8\u001b[0m canasta_basica_total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m132853.3\u001b[39m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Supongamos que cada hogar tiene en promedio 2 adultos equivalentes\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Puedes ajustar este valor según la estructura demográfica de los hogares en tus datos\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Calcular el ingreso necesario\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mingreso_necesario\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m canasta_basica_total \u001b[38;5;241m*\u001b[39m ad_equiv_por_hogar\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Guardar el DataFrame actualizado en un nuevo archivo Excel\u001b[39;00m\n\u001b[0;32m     17\u001b[0m output_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrespondieron_con_ingreso_necesario.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ad_equiv_por_hogar' is not defined"
     ]
    }
   ],
   "source": [
    "#1.4\n",
    "\n",
    "# Leer el archivo Excel donde están los datos filtrados\n",
    "file_path = 'respondieron.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Supongamos que Canasta Básica Total para un adulto equivalente es de $132.853,3 (según lo indicado)\n",
    "canasta_basica_total = 132853.3\n",
    "\n",
    "# Supongamos que cada hogar tiene en promedio 2 adultos equivalentes\n",
    "# Puedes ajustar este valor según la estructura demográfica de los hogares en tus datos\n",
    "\n",
    "# Calcular el ingreso necesario\n",
    "df['ingreso_necesario'] = canasta_basica_total * ad_equiv_por_hogar\n",
    "\n",
    "# Guardar el DataFrame actualizado en un nuevo archivo Excel\n",
    "output_file = 'respondieron_con_ingreso_necesario.xlsx'\n",
    "df.to_excel(output_file, index=False)\n",
    "\n",
    "# Mostrar un mensaje de confirmación\n",
    "print(f'Se ha guardado el archivo \"{output_file}\" con la columna \"ingreso_necesario\" agregada.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0eacbd8-031e-4b11-b038-62862841eb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.5\n",
    "\n",
    "# Leer el archivo Excel donde están los datos filtrados\n",
    "file_path = 'respondieron_con_ingreso_necesario.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Verificar que las columnas 'ITF' e 'ingreso_necesario' existan en el DataFrame\n",
    "if 'ITF' in df.columns and 'ingreso_necesario' in df.columns:\n",
    "    # Agregar la columna 'pobre'\n",
    "    df['pobre'] = (df['ITF'] < df['ingreso_necesario']).astype(int)\n",
    "    \n",
    "    # Contar cuántos son identificados como pobres\n",
    "    pobres_identificados = df['pobre'].sum()\n",
    "    \n",
    "    # Guardar el DataFrame actualizado en el mismo archivo Excel\n",
    "    df.to_excel(file_path, index=False)\n",
    "    \n",
    "    # Mostrar un mensaje con la cantidad de pobres identificados\n",
    "    print(f'Se ha actualizado el archivo \"{file_path}\" agregando la columna \"pobre\".')\n",
    "    print(f'Se identificaron {pobres_identificados} pobres.')\n",
    "else:\n",
    "    print(\"No se encontraron las columnas 'ITF' e 'ingreso_necesario' en el DataFrame.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97781cb-402a-4876-b220-99b179e23e94",
   "metadata": {},
   "source": [
    "Parte 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a77828-c226-4517-9775-b5d1166ac1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.1\n",
    "import pandas as pd\n",
    "\n",
    "# Función para eliminar columnas relacionadas con ingresos\n",
    "def eliminar_columnas_ingresos(df):\n",
    "    # Lista de columnas a eliminar\n",
    "    columnas_a_eliminar = [\n",
    "        'ingreso_ocio', 'ingreso_tot', 'ing_otros', 'ing_tot_i', \n",
    "        'ing_no_lab', 'ing_tot_fam', 'ing_per_cap', \n",
    "        'ad_equiv_hogar', 'adulto_equiv', 'ingreso_necesario'\n",
    "    ]\n",
    "    \n",
    "    # Eliminar las columnas del DataFrame\n",
    "    df = df.drop(columns=columnas_a_eliminar, errors='ignore')\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Archivo donde están los datos filtrados\n",
    "archivo_respondieron = 'respondieron.xlsx'\n",
    "archivo_norespondieron = 'norespondieron.xlsx'\n",
    "\n",
    "# Leer archivos Excel y eliminar columnas relacionadas con ingresos\n",
    "df_respondieron = pd.read_excel(archivo_respondieron)\n",
    "df_respondieron = eliminar_columnas_ingresos(df_respondieron)\n",
    "\n",
    "df_norespondieron = pd.read_excel(archivo_norespondieron)\n",
    "df_norespondieron = eliminar_columnas_ingresos(df_norespondieron)\n",
    "\n",
    "# Guardar los DataFrames actualizados\n",
    "df_respondieron.to_excel('respondieron_sin_ingresos.xlsx', index=False)\n",
    "df_norespondieron.to_excel('norespondieron_sin_ingresos.xlsx', index=False)\n",
    "\n",
    "# Mostrar mensaje de confirmación\n",
    "print('Se han eliminado las columnas relacionadas con ingresos y se han guardado los archivos actualizados.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e95e35d-7b06-43ac-bcbc-6a7023bc843c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Leer el archivo Excel donde están los datos filtrados\n",
    "file_path = 'respondieron_sin_ingresos.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Agregar columna de unos (intercepto)\n",
    "df['intercepto'] = 1\n",
    "\n",
    "# Definir X (variables independientes) y y (variable dependiente)\n",
    "X = df.drop(columns=['pobre'])\n",
    "y = df['pobre']\n",
    "\n",
    "# Partir la base en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\n",
    "\n",
    "# Mostrar las dimensiones de los conjuntos de entrenamiento y prueba\n",
    "print(f'Dimensiones de X_train: {X_train.shape}')\n",
    "print(f'Dimensiones de X_test: {X_test.shape}')\n",
    "print(f'Dimensiones de y_train: {y_train.shape}')\n",
    "print(f'Dimensiones de y_test: {y_test.shape}')\n",
    "\n",
    "# Mostrar mensaje de confirmación\n",
    "print('Se han dividido los datos en conjuntos de entrenamiento y prueba correctamente.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88d9123-0bf0-4b95-af5f-62e155ebe3cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
